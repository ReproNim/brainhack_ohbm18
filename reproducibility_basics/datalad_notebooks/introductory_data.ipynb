{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versioning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will look at using tools to version data. Specifically, [git-annex](https://git-annex.branchable.com/) and [datalad](http://datalad.org/)\n",
    "\n",
    "- Initializing, searching, downloading, and removing (dropping) a datalad dataset\n",
    "- Creating and modifying a datalad dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by using the shell version\n",
    "\n",
    "**The `!` character at the beginning of the next line indicates that the subsequent command will be executed in a shell. We will be also using `%%bash` to run a multi-line expression.** \n",
    "\n",
    "In the following section we are generating the help command. The `--help-np` option ensures that the underlying help output does not page. Since the notebook does not support paging, we will be using this option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be typing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: datalad [global-opts] command [command-opts]\r\n",
      "\r\n",
      "Comprehensive data management solution\r\n",
      "\r\n",
      "DataLad provides a unified data distribution system built on the Git\r\n",
      "and Git-annex. DataLad command line tools allow to manipulate (obtain,\r\n",
      "create, update, publish, etc.) datasets and provide a comprehensive\r\n",
      "toolbox for joint management of data and code. Compared to Git/annex\r\n",
      "it primarly extends their functionality to transparently and\r\n",
      "simultaneously work with multiple inter-related repositories.\r\n",
      "\r\n",
      "*Commands for dataset operations*\r\n",
      "\r\n",
      "  create\r\n",
      "      Create a new dataset from scratch\r\n",
      "  install\r\n",
      "      Install a dataset from a (remote) source\r\n",
      "  get\r\n",
      "      Get any dataset content (files/directories/subdatasets)\r\n",
      "  add\r\n",
      "      Add files/directories to an existing dataset\r\n",
      "  publish\r\n",
      "      Publish a dataset to a known sibling\r\n",
      "  uninstall\r\n",
      "      Uninstall subdatasets\r\n",
      "  drop\r\n",
      "      Drop file content from datasets\r\n",
      "  remove\r\n",
      "      Remove components from datasets\r\n",
      "  update\r\n",
      "      Update a dataset from a sibling\r\n",
      "  create-sibling\r\n",
      "      Create a dataset sibling on a UNIX-like SSH-accessible machine\r\n",
      "  create-sibling-github\r\n",
      "      Create dataset sibling on Github\r\n",
      "  unlock\r\n",
      "      Unlock file(s) of a dataset\r\n",
      "  save\r\n",
      "      Save the current state of a dataset\r\n",
      "\r\n",
      "*Commands for metadata handling*\r\n",
      "\r\n",
      "  search\r\n",
      "      Search dataset metadata\r\n",
      "  metadata\r\n",
      "      Metadata reporting for files and entire datasets\r\n",
      "  aggregate-metadata\r\n",
      "      Aggregate metadata of one or more datasets for later query\r\n",
      "  extract-metadata\r\n",
      "      Run one or more of DataLad's metadata extractors on a dataset or file\r\n",
      "\r\n",
      "*Miscellaneous commands*\r\n",
      "\r\n",
      "  test\r\n",
      "      Run internal DataLad (unit)tests\r\n",
      "  ls\r\n",
      "      List summary information about URLs and dataset(s)\r\n",
      "  clean\r\n",
      "      Clean up after DataLad (possible temporary files etc.)\r\n",
      "  add-archive-content\r\n",
      "      Add content of an archive under git annex control\r\n",
      "  download-url\r\n",
      "      Download content\r\n",
      "  run\r\n",
      "      Run an arbitrary shell command and record its impact on a dataset\r\n",
      "  rerun\r\n",
      "      Re-execute previous `datalad run` commands\r\n",
      "  run-procedure\r\n",
      "      Run prepared procedures (DataLad scripts) on a dataset\r\n",
      "\r\n",
      "*Plugins*\r\n",
      "\r\n",
      "  no-annex\r\n",
      "      Configure a dataset to never put some content into the dataset's\r\n",
      "      annex\r\n",
      "  addurls\r\n",
      "      Create and update a dataset from a list of URLs\r\n",
      "  add-readme\r\n",
      "      Add basic information about DataLad datasets to a README file\r\n",
      "  wtf\r\n",
      "      Generate a report about the DataLad installation and configuration\r\n",
      "  export-archive\r\n",
      "      Export the content of a dataset as a TAR/ZIP archive\r\n",
      "  check-dates\r\n",
      "      Find repository dates that are more recent than a reference date\r\n",
      "  export-to-figshare\r\n",
      "      Export the content of a dataset as a ZIP archive to figshare\r\n",
      "\r\n",
      "*Plumbing commands*\r\n",
      "\r\n",
      "  annotate-paths\r\n",
      "      Analyze and act upon input paths\r\n",
      "  clone\r\n",
      "      Obtain a dataset copy from a URL or local source (path)\r\n",
      "  create-test-dataset\r\n",
      "      Create test (meta-)dataset\r\n",
      "  diff\r\n",
      "      Report changes of dataset components\r\n",
      "  siblings\r\n",
      "      Manage sibling configuration\r\n",
      "  sshrun\r\n",
      "      Run command on remote machines via SSH\r\n",
      "  subdatasets\r\n",
      "      Report subdatasets and their properties\r\n",
      "\r\n",
      "*General information*\r\n",
      "\r\n",
      "Detailed usage information for individual commands is available via\r\n",
      "command-specific --help, i.e.: datalad <command> --help\r\n",
      "\r\n",
      "\r\n",
      "*Global options*\r\n",
      "  -l LEVEL, --log-level LEVEL\r\n",
      "                        set logging verbosity level. Choose among critical,\r\n",
      "                        error, warning, info, debug. Also you can specify an\r\n",
      "                        integer <10 to provide even more debugging information\r\n",
      "  --pbs-runner {condor}\r\n",
      "                        execute command by scheduling it via available PBS.\r\n",
      "                        For settings, config file will be consulted\r\n",
      "  -C PATH               run as if datalad was started in <path> instead of the\r\n",
      "                        current working directory. When multiple -C options\r\n",
      "                        are given, each subsequent non-absolute -C <path> is\r\n",
      "                        interpreted relative to the preceding -C <path>. This\r\n",
      "                        option affects the interpretations of the path names\r\n",
      "                        in that they are made relative to the working\r\n",
      "                        directory caused by the -C option\r\n",
      "  --version             show the program's version and license information\r\n",
      "  --dbg                 enter Python debugger when uncaught exception happens\r\n",
      "  --idbg                enter IPython debugger when uncaught exception happens\r\n",
      "  -c KEY=VALUE          configuration variable setting. Overrides any\r\n",
      "                        configuration read from a file, but is potentially\r\n",
      "                        overridden itself by configuration variables in the\r\n",
      "                        process environment.\r\n",
      "  -f {default,json,json_pp,tailored,'<template>'}, --output-format {default,json,json_pp,tailored,'<template>'}\r\n",
      "                        select format for returned command results. 'default'\r\n",
      "                        give one line per result reporting action, status,\r\n",
      "                        path and an optional message; 'json' renders a JSON\r\n",
      "                        object with all properties for each result (one per\r\n",
      "                        line); 'json_pp' pretty-prints JSON spanning multiple\r\n",
      "                        lines; 'tailored' enables a command-specific rendering\r\n",
      "                        style that is typically tailored to human consumption\r\n",
      "                        (no result output otherwise), '<template>' reports any\r\n",
      "                        value(s) of any result properties in any format\r\n",
      "                        indicated by the template (e.g. '{path}'; compare with\r\n",
      "                        JSON output for all key-value choices). The template\r\n",
      "                        syntax follows the Python \"format() language\". It is\r\n",
      "                        possible to report individual dictionary values, e.g.\r\n",
      "                        '{metadata[name]}'. If a 2nd-level key contains a\r\n",
      "                        colon, e.g. 'music:Genre', ':' must be substituted by\r\n",
      "                        '#' in the template, like so:\r\n",
      "                        '{metadata[music#Genre]}'.\r\n",
      "  --report-status {success,failure,ok,notneeded,impossible,error}\r\n",
      "                        constrain command result report to records matching\r\n",
      "                        the given status. 'success' is a synonym for 'ok' OR\r\n",
      "                        'notneeded', 'failure' stands for 'impossible' OR\r\n",
      "                        'error'.\r\n",
      "  --report-type {dataset,file}\r\n",
      "                        constrain command result report to records matching\r\n",
      "                        the given type. Can be given more than once to match\r\n",
      "                        multiple types.\r\n",
      "  --on-failure {ignore,continue,stop}\r\n",
      "                        when an operation fails: 'ignore' and continue with\r\n",
      "                        remaining operations, the error is logged but does not\r\n",
      "                        lead to a non-zero exit code of the command;\r\n",
      "                        'continue' works like 'ignore', but an error causes a\r\n",
      "                        non-zero exit code; 'stop' halts on first failure and\r\n",
      "                        yields non-zero exit code. A failure is any result\r\n",
      "                        with status 'impossible' or 'error'.\r\n",
      "  --proc-pre <PROCEDURE NAME> [ARGS ...]\r\n",
      "                        Dataset procedure to run before the main command (see\r\n",
      "                        run-procedure command for details). This option can be\r\n",
      "                        given more than once to run multiple procedures in the\r\n",
      "                        order in which they were given. It is important to\r\n",
      "                        specify the target dataset via the --dataset argument\r\n",
      "                        of the main command.\r\n",
      "  --proc-post <PROCEDURE NAME> [ARGS ...]\r\n",
      "                        Like --proc-pre, but procedures are executed after the\r\n",
      "                        main command has finished.\r\n",
      "  --cmd                 syntactical helper that can be used to end the list of\r\n",
      "                        global command line options before the subcommand\r\n",
      "                        label. Options like --proc-pre can take an arbitrary\r\n",
      "                        number of arguments and may require to be followed by\r\n",
      "                        a single --cmd in order to enable identification of\r\n",
      "                        the subcommand.\r\n",
      "  -h, --help, --help-np\r\n",
      "                        show this help message. --help-np forcefully disables\r\n",
      "                        the use of a pager for displaying the help message\r\n",
      "\r\n",
      "\"Be happy!\"\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!datalad --help-np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Generate the help for the install command of datalad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# write your solution here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "solution2": "shown"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: datalad install [-h] [-s SOURCE] [-d DATASET] [-g] [-D DESCRIPTION]\r\n",
      "                       [-r] [--recursion-limit LEVELS] [--nosave] [--reckless]\r\n",
      "                       [-J NJOBS]\r\n",
      "                       [PATH [PATH ...]]\r\n",
      "\r\n",
      "Install a dataset from a (remote) source.\r\n",
      "\r\n",
      "This command creates a local sibling of an existing dataset from a\r\n",
      "(remote) location identified via a URL or path. Optional recursion into\r\n",
      "potential subdatasets, and download of all referenced data is supported.\r\n",
      "The new dataset can be optionally registered in an existing\r\n",
      "superdataset by identifying it via the DATASET argument (the new\r\n",
      "dataset's path needs to be located within the superdataset for that).\r\n",
      "\r\n",
      "It is recommended to provide a brief description to label the dataset's\r\n",
      "nature *and* location, e.g. \"Michael's music on black laptop\". This helps\r\n",
      "humans to identify data locations in distributed scenarios.  By default an\r\n",
      "identifier comprised of user and machine name, plus path will be generated.\r\n",
      "\r\n",
      "When only partial dataset content shall be obtained, it is recommended to\r\n",
      "use this command without the GET-DATA flag, followed by a\r\n",
      "`get` operation to obtain the desired data.\r\n",
      "\r\n",
      "NOTE\r\n",
      "  Power-user info: This command uses git clone, and\r\n",
      "  git annex init to prepare the dataset. Registering to a\r\n",
      "  superdataset is performed via a git submodule add operation\r\n",
      "  in the discovered superdataset.\r\n",
      "\r\n",
      "*Arguments*\r\n",
      "  PATH                  path/name of the installation target. If no PATH is\r\n",
      "                        provided a destination path will be derived from a\r\n",
      "                        source URL similar to git clone. [Default: None]\r\n",
      "\r\n",
      "*Options*\r\n",
      "  -h, --help, --help-np\r\n",
      "                        show this help message. --help-np forcefully disables\r\n",
      "                        the use of a pager for displaying the help message\r\n",
      "  -s SOURCE, --source SOURCE\r\n",
      "                        URL or local path of the installation source.\r\n",
      "                        Constraints: value must be a string [Default: None]\r\n",
      "  -d DATASET, --dataset DATASET\r\n",
      "                        specify the dataset to perform the install operation\r\n",
      "                        on. If no dataset is given, an attempt is made to\r\n",
      "                        identify the dataset in a parent directory of the\r\n",
      "                        current working directory and/or the PATH given.\r\n",
      "                        Constraints: Value must be a Dataset or a valid\r\n",
      "                        identifier of a Dataset (e.g. a path) [Default: None]\r\n",
      "  -g, --get-data        if given, obtain all data content too. [Default:\r\n",
      "                        False]\r\n",
      "  -D DESCRIPTION, --description DESCRIPTION\r\n",
      "                        short description to use for a dataset location. Its\r\n",
      "                        primary purpose is to help humans to identify a\r\n",
      "                        dataset copy (e.g., \"mike's dataset on lab server\").\r\n",
      "                        Note that when a dataset is published, this\r\n",
      "                        information becomes available on the remote side.\r\n",
      "                        Constraints: value must be a string [Default: None]\r\n",
      "  -r, --recursive       if set, recurse into potential subdataset. [Default:\r\n",
      "                        False]\r\n",
      "  --recursion-limit LEVELS\r\n",
      "                        limit recursion into subdataset to the given number of\r\n",
      "                        levels. Constraints: value must be convertible to type\r\n",
      "                        'int' [Default: None]\r\n",
      "  --nosave              by default all modifications to a dataset are\r\n",
      "                        immediately saved. Giving this option will disable\r\n",
      "                        this behavior. [Default: True]\r\n",
      "  --reckless            Set up the dataset to be able to obtain content in the\r\n",
      "                        cheapest/fastest possible way, even if this poses a\r\n",
      "                        potential risk the data integrity (e.g. hardlink files\r\n",
      "                        from a local clone of the dataset). Use with care, and\r\n",
      "                        limit to \"read-only\" use cases. With this flag the\r\n",
      "                        installed dataset will be marked as untrusted.\r\n",
      "                        [Default: False]\r\n",
      "  -J NJOBS, --jobs NJOBS\r\n",
      "                        how many parallel jobs (where possible) to use.\r\n",
      "                        Constraints: value must be convertible to type 'int',\r\n",
      "                        or value must be one of ('auto',) [Default: None]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!datalad install --help-np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datalad install\n",
    "\n",
    "We will install the datalad metadataset. Note this only installs the top level directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "install(ok): /home/neuro/data/datasets.datalad.org (dataset)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Cloning http://datasets.datalad.org/ to '/home/neuro/data/datasets.datalad.org' \n",
      "[WARNING] It is highly recommended to configure git first (set both user.name and user.email) before using DataLad. Failed to verify that git is configured: CommandError: command '['git', 'config', 'user.name']' failed with exitcode 1\n",
      "| Failed to run ['git', 'config', 'user.name'] under None. Exit code=1. out= err= [cmd.py:run:530]CommandError: command '['git', 'config', 'user.email']' failed with exitcode 1\n",
      "| Failed to run ['git', 'config', 'user.email'] under None. Exit code=1. out= err= [cmd.py:run:530].  Some operations might fail or not perform correctly. \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir ~/data\n",
    "cd ~/data\n",
    "datalad install /// "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "\n",
    "List the contents of the installed dataset using the tree command up to three levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# write your solution here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/neuro/data/datasets.datalad.org/\n",
      "├── abide\n",
      "├── abide2\n",
      "├── adhd200\n",
      "├── corr\n",
      "├── crcns\n",
      "├── datapackage.json\n",
      "├── dbic\n",
      "├── devel\n",
      "├── dicoms\n",
      "├── hbnssi\n",
      "├── indi\n",
      "├── kaggle\n",
      "├── labs\n",
      "├── neurovault\n",
      "├── nidm\n",
      "├── openfmri\n",
      "└── workshops\n",
      "\n",
      "16 directories, 1 file\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "tree -L 3 ~/data/datasets.datalad.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that only the top level datasets are created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dtalad search\n",
    "Another useful command is to `search` for information across datalad datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's start from displaying the help for the search command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!datalad search --help-np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's search for datasets containing information about Jim Haxby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!datalad search -d ~/data/datasets.datalad.org haxby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3:\n",
    "\n",
    "Search for information about datasets related to chris gorgolewski, using `gorgolewski` as the keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "#type your solution here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "!datalad search -d ~/data/datasets.datalad.org gorgolewski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4:\n",
    "\n",
    "Install one of the dataset - ds0000114 and look at the contents of the dataset upto three levels using the tree command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# type your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "datalad install ~/data/datasets.datalad.org/workshops/nih-2017/ds000114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "!tree -L 3 ~/data/datasets.datalad.org/workshops/nih-2017/ds000114"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we try to check the content of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ~/data/datasets.datalad.org/workshops/nih-2017/ds000114/dwi.bval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got `No such file or directory`, because we only installed the dataset, but we didn't download anything!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datalad get\n",
    "Let's use datalad to fetch this file and then list it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!datalad get ~/data/datasets.datalad.org/workshops/nih-2017/ds000114/dwi.bval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and let's try to get the content again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ~/data/datasets.datalad.org/workshops/nih-2017/ds000114/dwi.bval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!datalad ls ~/data/datasets.datalad.org/workshops/nih-2017/ds000114"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gitt-annex list\n",
    "\n",
    "Since datalad uses git-annex under the hood, let's try to list things with git-annex. Let's first check the help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git-annex list --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and try to list all flies from `sub-01` in `ds000114`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git-annex list ~/data/datasets.datalad.org/workshops/nih-2017/ds000114/sub-01/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! Git and datalad don't recognize root folders without pointing to an annex or dataset location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd ~/data/datasets.datalad.org/workshops/nih-2017/ds000114/\n",
    "git-annex list sub-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6:\n",
    "\n",
    "Show the help for `git annex list` and then use it to list the `dwi*` files in `ds000114`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# type your solution here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ~/data/datasets.datalad.org/workshops/nih-2017/ds000114/\n",
    "git-annex list dwi.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datalad drop\n",
    "We can also remove content from our local storage using the `drop` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!datalad drop ~/data/datasets.datalad.org/workshops/nih-2017/ds000114/dwi.bval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see that the file is still listed under the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l ~/data/datasets.datalad.org/workshops/nih-2017/ds000114/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but we can't access the content again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat ~/data/datasets.datalad.org/workshops/nih-2017/ds000114/dwi.bval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7:\n",
    "\n",
    "Check where the dwi files are with the annex list command and get the missing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "#type your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ~/data/datasets.datalad.org/workshops/nih-2017/ds000114/\n",
    "git-annex list dwi.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "datalad get ~/data/datasets.datalad.org/workshops/nih-2017/ds000114/dwi.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and versioning our own dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datalad create\n",
    "Let's create dataset called `mydataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!datalad create ~/data/mydataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a dummy file and add it to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "echo \"123\" > ~/data/mydataset/123\n",
    "datalad add -m \"initial file\" ~/data/mydataset/123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list where the copy is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ~/data/mydataset\n",
    "git-annex list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree ~/data/mydataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ~/data/mydataset/.git/annex/objects/pF/Zf/MD5E-s4--ba1f2511fc30423bdbb183fe33f3dd0f/MD5E-s4--ba1f2511fc30423bdbb183fe33f3dd0f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try removing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!datalad drop ~/data/mydataset/123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datalad will prevent from doing this, because this is the only copy of the file. It will also not allow to modify the file so easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"321\" > ~/data/mydataset/123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we really want to change the content of the file, we have to unlock the file first. After changes we should commit it back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "datalad unlock ~/data/mydataset/123\n",
    "echo \"321\" > ~/data/mydataset/123\n",
    "datalad add -m \"add modified file\" ~/data/mydataset/123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try modifying it, we now again get permission denied, because the file is locked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"123\" > ~/data/mydataset/123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree ~/data/mydataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ~/data/mydataset/.git/annex/objects/6v/gZ/MD5E-s4--9492fe88f263d58e0b686885e8c98c0e/MD5E-s4--9492fe88f263d58e0b686885e8c98c0e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the old object is still there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ~/data/mydataset/.git/annex/objects/pF/Zf/MD5E-s4--ba1f2511fc30423bdbb183fe33f3dd0f/MD5E-s4--ba1f2511fc30423bdbb183fe33f3dd0f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire history of the repo is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "cd ~/data/mydataset/\n",
    "git log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a simple script that counts the number of characters in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ~/data/mydataset\n",
    "mkdir -p scripts\n",
    "cmd=$(cat << EOM\n",
    "#!/bin/bash\\ncat \\$1 | wc -c\n",
    "EOM\n",
    ")\n",
    "echo -e $cmd > scripts/run.sh\n",
    "chmod +x scripts/run.sh\n",
    "cat scripts/run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run the script and add the script and the output to annex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ~/data/mydataset\n",
    "scripts/run.sh 123 > out\n",
    "datalad add -m \"Added scripts and output\" out scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the log again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "cd ~/data/mydataset/\n",
    "git log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go back to a previous state and check the contents of the `123` file. Note that we return back to current state after this excursion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "tree ~/data/mydataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - dj\n",
    "%%bash\n",
    "\n",
    "cd ~/data/mydataset/\n",
    "git checkout 8cdcf1758\n",
    "tree ~/data/mydataset/\n",
    "git checkout master\n",
    "tree ~/data/mydataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "## Exercise 8:\n",
    "\n",
    "- Copy one binary brainmask image file from ds000114/derivatives/fmriprep into mydataset\n",
    "  - To do so first you should install the dataset recursively\n",
    "  - And then get the file\n",
    "- Add to version control\n",
    "- use git-annex to list where that file can be found\n",
    "- Add a simple python script to count and print the number of non-zero voxels\n",
    "- Store the output into a new out file\n",
    "- Use datalad to add everything to the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "datalad install -r /data/datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/fmriprep/\n",
    "tree -L 1 /data/datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/fmriprep/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "tree -L 1 /data/datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/fmriprep/sub-01/anat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "datalad get /data/datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/fmriprep/sub-01/anat/sub-01_t1w_brainmask.nii.gz\n",
    "cp /data/datasets.datalad.org/workshops/nih-2017/ds000114/derivatives/fmriprep/sub-01/anat/sub-01_t1w_brainmask.nii.gz \\\n",
    "   /data/mydataset/brainmask.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "%%writefile /data/mydataset/scripts/count_voxels.py\n",
    "\n",
    "import nibabel as nb\n",
    "import sys\n",
    "print(nb.load(sys.argv[1]).get_data().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /data/mydataset/\n",
    "python scripts/count_voxels.py brainmask.nii.gz > mask_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "tree /data/mydataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /data/mydataset/\n",
    "datalad add -m \"added brainmask, script, and output\" brainmask.nii.gz scripts/count_voxels.py mask_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /data/mydataset/\n",
    "git-annex whereis brainmask.nii.gz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
